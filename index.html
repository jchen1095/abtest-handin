<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AB Testing Hand-in</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>AB Testing Hand-in</h1>
    </header>
    <main>
        <section id="Modified Website">
            <h3>Purpose Statement</h3>
            <p>Through this project, I want to evaluate if the usability of Version B of the website is greater than the usability of Version A for scheduling an appointment. Conducting AB Testing is useful for this task as it involves analyzing several metrics and features of the websites and using statistical tests to analyze if there is a significant difference in the efficacy of the website design.</p>
            <p>Below is the image of my modified Version B website. The colors of the buttons were changed and the spacing in between the date and the buttons in the scheduling column were decreased. Moreover, when buttons are hovered over, the buttons increase in size slightly.</p>
            <img src="btest.png" width="700" height="300">
        </section>
        <h2>Hypotheses</h2>
        <section id="Hypotheses">
            <p>Below are the hypothesis for our metrics when comparing Version A and Version B.</p>
            <h3>Misclick Occurance</h3>
            <p>Null Hypothesis: The misclick occurance for Version B and Version A are not significantly different when compared to each other.</p>
            <p>Alternative Hypothesis: The misclick occurance for Version A is significantly higher than Version B.</p>
            <p>Justification for alternative hypothesis: Since the buttons were made to have higher contrast and to have hover effects for enhanced indications of button selection, users should now find the website more readable and therefore should be able to complete the task more effectively. In other words, users should be able to complete the task with less misclicks.</p>
            <p>Prediction: I predict that the misclick occurance will decrease by a statistically significant amount due to the website improvements, which will lead my to reject the null hypothesis.</p>
            <h3>Time On Page</h3>
            <p>Null Hypothesis: The time spent on the page in milliseconds for Version B and Version A of the website are relatively the same, or not significantly different.</p>
            <p>Alternative Hypothesis: The time spent on Version B is much lower than the time spent on Version A.</p>
            <p>Justification for alternative hypothesis: Similar to the reasoning above, since the information on the website is less spaced out and more grouped together, and since the buttons are more interactive due to higher contrast and hover effects, the users should be able to find the correct appointment and complete the task in less amount of time because the website's spacing and visuals are easier to process.</p>
            <p>Prediction: I predict that I will reject the null hypothesis because the time spent on Version B will be lower by statistically significant amount due to the improvements in the website creating a more efficient and user-friendly experience</p>
            <h3>Mouse Move Distance</h3>
            <p>The mouse move distance is the measurement of the total distance, in pixels, of the user's mouse movements. This metric is significant because mouse move distance should be lower if the user is more efficient with their interactions on the website.</p>
            <p>Null Hypothesis: The average mouse move distance in pixels for Version B and Version A of the website are not statistically different.</p>
            <p>Alternative Hypothesis: The average mouse move distance for Version A is significantly higher than the average mouse move difference of Version B.</p>
            <p>Justification for alternative hypothesis: Since the website's middle column, with the scheduling information and buttons, are less spaced apart, the user's eye doesn't have to search as far to read and find the correct appointment. Since the user's reading time is optimized and the buttons are easier to find, the mouse move distance should decrease since the user does not have to search as much to complete their task. In other words, the user should be more efficient which should lead to less time spent physically using the mouse to search for the right appointment.</p>
            <p>Prediction: I predict that the average mouse move distance for Version B will be lower by a statistically significant amount and will lead me to reject the null hypothesis.</p>
        </section> 
        <h1>Statistical Tests</h1>
        <section id="Statistical Tests">
            <h2>Misclicks</h2>
            <h3>Reason for Type of Statistical Test</h3>
            <p>Since we are mostly interested in the direction of the change of misclicks, in other words whether the misclick occurance increases or decreases, we can use a one-tailed t-test to evaluate this metric.</p>
            <h3>Analysis</h3>
            <p>The average misclicks per user trial for Version A is 0.260869, whereas the average misclicks per user trial for Version B is 0.071428. There is a significant decrease in misclick occurance from Version A to Version B. Since the p-value, which is 0.041329, is less than 0.05, we know that the difference we see between the misclicks for Version A and Version B is statistically significant.</p>
            <p>This shows that there is substantial evidence for users experiencing less misclicks when using Version B compared to Version A</p>
            <h3>Conclusion</h3>
            <p>To conclude, I reject the null hypothesis that misclick occurance for Version B and Version A are not significantly different when compared to each other. Instead, I accept the alternative hypothesis as the evidence supports the alternative hypothesis.</p>
            <h2>Time Spent On Page</h2>
            <h3>Reason for Type of Statistical Test</h3>
            <p>Since we are interested in the direction of the change of time spent on page, in other words whether the time spent increases or decreases, we can use a one-tailed t-test to evaluate this metric as we don't necessarily need exact differences between the two measurements being compared.</p>
            <h3>Analysis</h3>
            <p>The p-value is 0.41986, which is much greater than a p-value of 0.05, thus we know that any differences in measurements of time spent on Version A and Version B are not statistically significant. For example, the average time spent on Version A is 22,324 milliseconds, and for Version B it is 24,511 milliseconds. According to the high p-value, these two averages are not very different.</p>
            <h3>Conclusion</h3>
            <p>Since the change in average time spent on page for Version A and Version B are not statistically different, we fail to reject the null hypothesis. Moreover, it is interesting that the average time spent on Version B was slightly longer than the average time spent for Version A. This could imply that differences in website versions impact user experience, but the p-values suggest that the differences are not statistically significant enough to provide sound evidence for this conclusion.</p>
            <h2>Mouse Move Distance</h2>
            <h3>Reason for Type of Statistical Test</h3>
            <p>We are interested in the specific/exact change of average mouse move distance on both page versions, so we need a two-tailed t-test to calculate and analyze the exact differences between the two measurements being compared.</p>
            <h3>Analysis</h3>
            <p>The average mouse move distance in pixels for Version A tests is 6471 pixels. The average mouse move distance in pixels for Version B tests is 2791 pixels. The p-value is 0.0011 which is less than 0.05, meaning that the difference in the average mouse movement distance is statistically different and provides evidence for user experience being impacted by the change from Version A to Version B.</p>
            <h3>Conclusion</h3>
            <p>In conclusion, we can reject the null hypothesis because there is a statistically significant difference between the average mouse move distances between the two versions of the website.</p>
        </section> 
        <h2>Summary Statistics</h2>
        <section id="Summary Statistics">
        <p>I collected around 23-28 data points, with 23 data points for Version A and 28 data points for Version B. Because the dataset sizes were similar, I do not believe they were imbalanced in a way that would make the metrics measured and analyzed less sound.</p>
        <p>The averages for time spent was around 22324 milliseconds for Version A and 24511 milliseconds for Version B. It is interesting that the average time spent was slightly higher for Version B, which could imply that the Version B website was more difficult for users to use, however the p-value is less than 0.05 which means the difference between average time spent is not statistically significant enough to conclude this.</p>
        <p>Moreover, the variance of both Version A and Version B time spent in milliseconds were very high, from 234839182.5-2934384210. This suggests that the data for time spent was very sparsly distributed, in other words each data point is often different from the other. This is also true for the amount of mouse movement distance, as the variance for both Version A and Version B are very high at 19773316.83 and 5665630.381, respectively.</p>
        <p>Again, this high variance suggests that the data for mouse movement distance is highly distributed and that there is a wide range of data point values. The averages for mouse move distance were statistically significant, with p-value less than 0.05 and the average mouse move distance for Version A being around 6471 pixels and for Version B being around 2791 pixels.</p>
        <p>The data for misclicks was converted from Booleans to 0 and 1 for False and True, respectively. Because of this, the variance was appropriate for Versions A and B at 0.201 and 0.068, respectively. These smaller variances mean that there is high similarities among the points, especially in Version B since the variance is very low. This may be because Version B had a significantly less amount of "True" entries for misclicks. Moreover, the averages for the occurance of misclicks followed a similar pattern, with the average of misclicks for Version A being 0.25086 and the average for Version B being 0.06878. Since the p-value is less than 0.05, this shows that there is a statistically significant decrease in misclicks in Version B compared to Version A.</p>
    </section> 
        <h2>Conclusion</h2>
        <section id="Conclusions">
            <p>In conclusion, statistics are very important for evaluating improvements and usability in websites, although they are definitely not the only evidence of the efficacy of a website. The type of statistical test is very important for obtaining a comprehensive understanding of the measured metrics and to appropriately assess the relationships between the measured metrics or the variables/versions of websites being compared.</p>
        </section> 
    </main>
</body>
</html>
